{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sEXO_IR5xKX",
        "outputId": "d2bba162-640c-4fb7-e54d-e154fa8ce071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU usage: 17.9\n",
            "Memory usage: 15.4\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "print(\"CPU usage:\", psutil.cpu_percent())\n",
        "print(\"Memory usage:\", psutil.virtual_memory().percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVlprJNc5xKa",
        "outputId": "9e799a9c-1967-406b-9755-cbf10a07ab45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "No TensorFlow GPU detected; TF will use CPU.\n",
            "PyTorch CUDA available: False\n",
            "Using PyTorch device: CPU\n"
          ]
        }
      ],
      "source": [
        "# GPU setup for TensorFlow and PyTorch (if available)\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(\"TensorFlow version:\", tf.__version__)\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "            print(f\"TensorFlow GPUs available: {len(gpus)} physical, {len(logical_gpus)} logical\")\n",
        "        except Exception as e:\n",
        "            print(\"Could not set TF GPU memory growth:\", e)\n",
        "    else:\n",
        "        print(\"No TensorFlow GPU detected; TF will use CPU.\")\n",
        "except Exception as e:\n",
        "    print(\"TensorFlow not available:\", e)\n",
        "\n",
        "# Optional PyTorch device setup if used later\n",
        "try:\n",
        "    import torch\n",
        "    torch_cuda = torch.cuda.is_available()\n",
        "    device = torch.device('cuda' if torch_cuda else 'cpu')\n",
        "    print(\"PyTorch CUDA available:\", torch_cuda)\n",
        "    if torch_cuda:\n",
        "        print(\"Using PyTorch device:\", torch.cuda.get_device_name(0))\n",
        "    else:\n",
        "        print(\"Using PyTorch device: CPU\")\n",
        "except Exception as e:\n",
        "    print(\"PyTorch not available:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "h-iwqHZE6583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1654634-7211-4225-b263-007d36afeac3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sJfkfJh95xKb"
      },
      "outputs": [],
      "source": [
        "# # GPU diagnostics and assertion: must run on GPU\n",
        "# import os, sys\n",
        "# print(\"Python:\", sys.version)\n",
        "\n",
        "# # TensorFlow check\n",
        "# try:\n",
        "#     import tensorflow as tf\n",
        "#     print(\"TensorFlow:\", tf.__version__)\n",
        "#     tf_gpus = tf.config.list_physical_devices('GPU')\n",
        "#     print(\"TF GPUs:\", tf_gpus)\n",
        "#     if tf_gpus:\n",
        "#         # Optional: enable device placement logging for clarity\n",
        "#         os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"1\")  # INFO\n",
        "#         try:\n",
        "#             for gpu in tf_gpus:\n",
        "#                 tf.config.experimental.set_memory_growth(gpu, True)\n",
        "#             logical = tf.config.list_logical_devices('GPU')\n",
        "#             print(f\"TF GPU ready: {len(tf_gpus)} physical, {len(logical)} logical\")\n",
        "#         except Exception as e:\n",
        "#             print(\"Warn: couldn't set TF memory growth:\", e)\n",
        "#     else:\n",
        "#         raise RuntimeError(\"TensorFlow GPU not detected. Install CUDA/cuDNN and correct env.\")\n",
        "# except Exception as e:\n",
        "#     raise RuntimeError(f\"TensorFlow check failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDuZsSQo5xKc"
      },
      "source": [
        "# Fake Image Detection using Error Level Analysis (ELA) and CNN\n",
        "\n",
        "This notebook implements a Convolutional Neural Network (CNN) to detect fake images by analyzing their compression artifacts using Error Level Analysis (ELA).\n",
        "\n",
        "### Prerequisite: Dataset Structure\n",
        "Ensure your dataset is uploaded and structured as follows:\n",
        "```\n",
        "dataset/\n",
        "├── train/\n",
        "│   ├── real/\n",
        "│   └── fake/\n",
        "├── validation/\n",
        "│   ├── real/\n",
        "│   └── fake/\n",
        "└── test/\n",
        "    ├── real/\n",
        "    └── fake/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "z0f-NFRX5xKd"
      },
      "outputs": [],
      "source": [
        "# If using Google Colab, uncomment the following lines to mount your drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Usi5f0SX5xKd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo3Qvz1f5xKd"
      },
      "source": [
        "## 1. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "otb6xg-m5xKe"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (256, 256)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "# Update this path to point to your dataset location\n",
        "DATASET_PATH = '/content/drive/MyDrive/Data Set 1/Data Set 1'\n",
        "\n",
        "# ELA settings\n",
        "ELA_QUALITY = 90  # try 70-95\n",
        "ELA_QUALITIES = None  # e.g., [80, 90, 95] to generate multiple versions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyHn98in5xKe"
      },
      "source": [
        "## 2. Error Level Analysis (ELA) Function\n",
        "This function resaves the image at a specific quality level and calculates the difference (error) between the original and the compressed version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "y8Nlt1a25xKe"
      },
      "outputs": [],
      "source": [
        "def convert_to_ela_image(path, quality=90):\n",
        "    temp_filename = \"temp_ela.jpg\"\n",
        "\n",
        "    try:\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        image.save(temp_filename, \"JPEG\", quality=quality)\n",
        "\n",
        "        compressed = Image.open(temp_filename)\n",
        "        ela_img = ImageChops.difference(image, compressed)\n",
        "\n",
        "        extrema = ela_img.getextrema()\n",
        "        max_diff = max([ex[1] for ex in extrema]) or 1\n",
        "        scale = 255.0 / max_diff\n",
        "\n",
        "        ela_img = ImageEnhance.Brightness(ela_img).enhance(scale)\n",
        "        return ela_img.resize(IMAGE_SIZE)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ELA ERROR] {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def build_ela_stack(path):\n",
        "    if ELA_QUALITIES and isinstance(ELA_QUALITIES, (list, tuple)):\n",
        "        imgs = []\n",
        "        for q in ELA_QUALITIES:\n",
        "            img = convert_to_ela_image(path, quality=q)\n",
        "            if img is not None:\n",
        "                imgs.append(np.array(img) / 255.0)\n",
        "        if len(imgs) > 0:\n",
        "            # stack along channel dimension\n",
        "            stacked = np.concatenate(imgs, axis=-1)\n",
        "            # if channels exceed 3, truncate to first 3 to fit current model\n",
        "            return stacked[..., :3]\n",
        "    # fallback single quality\n",
        "    img = convert_to_ela_image(path, quality=ELA_QUALITY)\n",
        "    return np.array(img) / 255.0 if img is not None else None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e8rU3YL5xKf"
      },
      "source": [
        "## 3. Frequency Domain Analysis (FFT)\n",
        "The FFT reveals periodic compression artifacts and copy-paste seams that may be subtle in the spatial domain. The cells below compute a log-magnitude spectrum and simple band energy statistics for each image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "WjKlWbdU5xKf"
      },
      "outputs": [],
      "source": [
        "def compute_frequency_map(img_path):\n",
        "    \"\"\"Return normalized log-magnitude FFT spectrum for the grayscale image.\"\"\"\n",
        "    image = Image.open(img_path).convert(\"L\").resize(IMAGE_SIZE)\n",
        "    spectrum = np.fft.fftshift(np.fft.fft2(image))\n",
        "    magnitude = 20 * np.log(np.abs(spectrum) + 1e-8)\n",
        "    normalized = (magnitude - magnitude.min()) / (np.ptp(magnitude) + 1e-8)\n",
        "    return normalized\n",
        "\n",
        "def band_energy_stats(freq_map, high_cut=0.6, mid_cut=0.3):\n",
        "    \"\"\"Compute average energy in low/mid/high frequency bands using radial masks.\"\"\"\n",
        "    h, w = freq_map.shape\n",
        "    cy, cx = h // 2, w // 2\n",
        "    y, x = np.ogrid[:h, :w]\n",
        "    radius = np.sqrt((x - cx) ** 2 + (y - cy) ** 2)\n",
        "    max_r = radius.max()\n",
        "\n",
        "    low_mask = radius <= mid_cut * max_r\n",
        "    mid_mask = (radius > mid_cut * max_r) & (radius <= high_cut * max_r)\n",
        "    high_mask = radius > high_cut * max_r\n",
        "\n",
        "    return {\n",
        "        \"low\": float(freq_map[low_mask].mean()),\n",
        "        \"mid\": float(freq_map[mid_mask].mean()),\n",
        "        \"high\": float(freq_map[high_mask].mean()),\n",
        "    }\n",
        "\n",
        "def visualize_frequency_analysis(img_path):\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"File not found: {img_path}\")\n",
        "        return\n",
        "\n",
        "    original = Image.open(img_path).resize(IMAGE_SIZE)\n",
        "    ela_img = convert_to_ela_image(img_path)\n",
        "    if ela_img is None:\n",
        "        print(f\"ELA failed for {img_path}\")\n",
        "        return\n",
        "\n",
        "    freq_map = compute_frequency_map(img_path)\n",
        "    energy = band_energy_stats(freq_map)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "    axes[0].imshow(original)\n",
        "    axes[0].set_title(\"Original\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(ela_img)\n",
        "    axes[1].set_title(\"ELA\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    axes[2].imshow(freq_map, cmap=\"magma\")\n",
        "    axes[2].set_title(\n",
        "        f\"Frequency magnitude\\n(low/mid/high): {energy['low']:.3f} / {energy['mid']:.3f} / {energy['high']:.3f}\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\n",
        "        f\"Energy stats for {img_path} -> low: {energy['low']:.3f}, mid: {energy['mid']:.3f}, high: {energy['high']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trWIKLUG5xKf"
      },
      "source": [
        "## 4. Data Loading Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "bj0PcOZr5xKf"
      },
      "outputs": [],
      "source": [
        "def load_split(split_path):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    classes = [\"real\", \"fake\"]\n",
        "\n",
        "    for label, class_name in enumerate(classes):\n",
        "        folder = os.path.join(split_path, class_name)\n",
        "\n",
        "        if not os.path.isdir(folder):\n",
        "            print(f\"[WARNING] Missing folder: {folder}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Loading '{class_name}' images from {split_path} ...\")\n",
        "\n",
        "        for filename in os.listdir(folder):\n",
        "            if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(folder, filename)\n",
        "            ela_img = convert_to_ela_image(img_path)\n",
        "\n",
        "            if ela_img:\n",
        "                X.append(np.array(ela_img) / 255.0)\n",
        "                Y.append(label)\n",
        "\n",
        "    return np.array(X), to_categorical(Y, 2)\n",
        "\n",
        "\n",
        "def load_freq_split(split_path):\n",
        "    X = []\n",
        "    Y = []\n",
        "    classes = [\"real\", \"fake\"]\n",
        "\n",
        "    for label, class_name in enumerate(classes):\n",
        "        folder = os.path.join(split_path, class_name)\n",
        "        if not os.path.isdir(folder):\n",
        "            print(f\"[WARNING] Missing folder: {folder}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Loading '{class_name}' frequency images from {split_path} ...\")\n",
        "        for filename in os.listdir(folder):\n",
        "            if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                continue\n",
        "\n",
        "            img_path = os.path.join(folder, filename)\n",
        "            freq_map = compute_frequency_map(img_path)\n",
        "            if freq_map is not None:\n",
        "                X.append(freq_map[..., np.newaxis])  # add channel dim\n",
        "                Y.append(label)\n",
        "\n",
        "    return np.array(X), to_categorical(Y, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9UJxIWH5xKf"
      },
      "source": [
        "## 5. Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tows2X1f5xKg",
        "outputId": "7db939f6-ca20-48ed-ea6f-2b3293d1c98a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== LOADING TRAIN DATA =====\n",
            "Loading 'real' images from /content/drive/MyDrive/Data Set 1/Data Set 1/train ...\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n===== LOADING TRAIN DATA =====\")\n",
        "x_train, y_train = load_split(os.path.join(DATASET_PATH, \"train\"))\n",
        "print(\"\\n===== LOADING TRAIN (FREQ) DATA =====\")\n",
        "x_train_freq, y_train_freq = load_freq_split(os.path.join(DATASET_PATH, \"train\"))\n",
        "\n",
        "print(\"\\n===== LOADING VALIDATION DATA =====\")\n",
        "x_val, y_val = load_split(os.path.join(DATASET_PATH, \"validation\"))\n",
        "print(\"\\n===== LOADING VALIDATION (FREQ) DATA =====\")\n",
        "x_val_freq, y_val_freq = load_freq_split(os.path.join(DATASET_PATH, \"validation\"))\n",
        "\n",
        "print(\"\\n===== LOADING TEST DATA =====\")\n",
        "x_test, y_test = load_split(os.path.join(DATASET_PATH, \"test\"))\n",
        "print(\"\\n===== LOADING TEST (FREQ) DATA =====\")\n",
        "x_test_freq, y_test_freq = load_freq_split(os.path.join(DATASET_PATH, \"test\"))\n",
        "\n",
        "print(\"\\nDataset Summary:\")\n",
        "print(f\"Train: {len(x_train)} images | Freq: {len(x_train_freq)} images\")\n",
        "print(f\"Validation: {len(x_val)} images | Freq: {len(x_val_freq)} images\")\n",
        "print(f\"Test: {len(x_test)} images | Freq: {len(x_test_freq)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkR5dhjR5xKg"
      },
      "source": [
        "## 6. Build CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYxnHTSg5xKg"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')   # real vs fake\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        " )\n",
        "\n",
        "freq_model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "freq_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        " )\n",
        "\n",
        "print(\"ELA model:\")\n",
        "model.summary()\n",
        "print(\"\\nFrequency model:\")\n",
        "freq_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djYesoSv5xKg"
      },
      "source": [
        "## 7. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NTAeZct5xKg"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
        "    ModelCheckpoint('best_ela_model.h5', monitor='val_accuracy', save_best_only=True)\n",
        "]\n",
        "\n",
        "callbacks_freq = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=8, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
        "    ModelCheckpoint('best_freq_model.h5', monitor='val_accuracy', save_best_only=True)\n",
        "]\n",
        "\n",
        "if len(x_train) > 0:\n",
        "    print(\"\\n===== STARTING TRAINING (ELA) =====\")\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        ")\n",
        "else:\n",
        "    print(\"No ELA training data found. Please check your DATASET_PATH.\")\n",
        "\n",
        "if len(x_train_freq) > 0:\n",
        "    print(\"\\n===== STARTING TRAINING (FREQ) =====\")\n",
        "    history_freq = freq_model.fit(\n",
        "        x_train_freq, y_train_freq,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=(x_val_freq, y_val_freq),\n",
        "        callbacks=callbacks_freq,\n",
        "        verbose=1\n",
        ")\n",
        "else:\n",
        "    print(\"No frequency training data found. Please check your DATASET_PATH.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWhi4GQO5xKg"
      },
      "source": [
        "## 8. Performance Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP6IYo3k5xKh"
      },
      "outputs": [],
      "source": [
        "def visualize_frequency_analysis(img_path):\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"File not found: {img_path}\")\n",
        "        return\n",
        "\n",
        "    # ---------------------------\n",
        "    # Load original + ELA\n",
        "    # ---------------------------\n",
        "    original = Image.open(img_path).resize(IMAGE_SIZE)\n",
        "\n",
        "    ela_img = convert_to_ela_image(img_path)\n",
        "    if ela_img is None:\n",
        "        print(f\"ELA failed for {img_path}\")\n",
        "        return\n",
        "\n",
        "    # ---------------------------\n",
        "    # Compute FFT + band energies\n",
        "    # ---------------------------\n",
        "    freq_map = compute_frequency_map(img_path)\n",
        "    energy = band_energy_stats(freq_map)\n",
        "\n",
        "    # ---------------------------\n",
        "    # COMPUTE RADIAL FFT PROFILE\n",
        "    # ---------------------------\n",
        "    h, w = freq_map.shape\n",
        "    cy, cx = h // 2, w // 2\n",
        "    y, x = np.indices((h, w))\n",
        "    radius = np.sqrt((x - cx)**2 + (y - cy)**2).astype(int)\n",
        "\n",
        "    radial_sum = np.bincount(radius.ravel(), freq_map.ravel())\n",
        "    radial_count = np.bincount(radius.ravel())\n",
        "    radial_profile = radial_sum / np.maximum(radial_count, 1)\n",
        "\n",
        "    # -------------------------------------\n",
        "    # CNN PREDICTION (FOR VISUALIZATION)\n",
        "    # -------------------------------------\n",
        "    # Convert ELA image → model input\n",
        "    ela_tensor = np.array(ela_img.resize(IMAGE_SIZE)).astype(\"float32\") / 255.0\n",
        "    ela_tensor = np.expand_dims(ela_tensor, axis=0)\n",
        "\n",
        "    pred = model.predict(ela_tensor)[0]    # [real_prob, fake_prob]\n",
        "    label = \"FORGED\" if pred[1] > pred[0] else \"REAL\"\n",
        "    conf = max(pred)\n",
        "\n",
        "    # ---------------------------\n",
        "    # PLOTS (5 panels)\n",
        "    # ---------------------------\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(26, 5))\n",
        "\n",
        "    # Original\n",
        "    axes[0].imshow(original)\n",
        "    axes[0].set_title(\"Original\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # ELA\n",
        "    axes[1].imshow(ela_img)\n",
        "    axes[1].set_title(\"ELA Output\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    # FFT Heatmap\n",
        "    axes[2].imshow(freq_map, cmap=\"magma\")\n",
        "    axes[2].set_title(\n",
        "        f\"FFT Magnitude\\nLow/Mid/High: {energy['low']:.3f} / \"\n",
        "        f\"{energy['mid']:.3f} / {energy['high']:.3f}\"\n",
        "    )\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    # FFT Radial Graph\n",
        "    axes[3].plot(radial_profile, linewidth=2)\n",
        "    axes[3].set_title(\"Radial FFT Frequency Profile\")\n",
        "    axes[3].set_xlabel(\"Radius → Frequency\")\n",
        "    axes[3].set_ylabel(\"Energy\")\n",
        "    axes[3].grid(True)\n",
        "\n",
        "    # CNN Prediction Panel\n",
        "    axes[4].axis(\"off\")\n",
        "    axes[4].text(\n",
        "        0.1,\n",
        "        0.5,\n",
        "        f\" CNN Prediction\\n\\n Label: {label}\\n Confidence: {conf:.3f}\\n\\nProbabilities:\\nReal: {pred[0]:.3f}\\nFake: {pred[1]:.3f}\",\n",
        "        fontsize=16,\n",
        "        bbox=dict(facecolor=\"white\", alpha=0.9)\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Terminal summary\n",
        "    print(f\"Energy stats for {img_path} → \"\n",
        "          f\"low: {energy['low']:.3f}, mid: {energy['mid']:.3f}, high: {energy['high']:.3f}\")\n",
        "    print(f\"CNN Prediction → {label} (confidence={conf:.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVlz6Uid5xKh"
      },
      "source": [
        "## 9. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIc2RJ345xKh"
      },
      "outputs": [],
      "source": [
        "if len(x_test) > 0:\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "    print(f\"\\n===== TEST ACCURACY (ELA): {test_acc * 100:.1f}% =====\")\n",
        "else:\n",
        "    print(\"No ELA test data available.\")\n",
        "\n",
        "if len(x_test_freq) > 0:\n",
        "    freq_test_loss, freq_test_acc = freq_model.evaluate(x_test_freq, y_test_freq)\n",
        "    print(f\"===== TEST ACCURACY (FREQ): {freq_test_acc * 100:.1f}% =====\")\n",
        "else:\n",
        "    print(\"No frequency test data available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCM7TndZ5xKh"
      },
      "source": [
        "## 10. Prediction Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4QTmo7n5xKh"
      },
      "outputs": [],
      "source": [
        "def predict_image(img_path, show=False):\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"Error: File not found -> {img_path}\")\n",
        "        return \"Unknown\", 0.0, None, None\n",
        "\n",
        "    original = Image.open(img_path).resize(IMAGE_SIZE)\n",
        "    ela_img = convert_to_ela_image(img_path, quality=ELA_QUALITY)\n",
        "    img_array = np.array(ela_img) / 255.0\n",
        "    img_array = img_array.reshape(1, IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
        "    pred = model.predict(img_array)\n",
        "    label = \"Forged\" if np.argmax(pred) == 1 else \"Real\"\n",
        "    confidence = float(np.max(pred))\n",
        "\n",
        "    if show:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(original)\n",
        "        plt.title(\"Original\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(ela_img)\n",
        "        plt.title(f\"ELA\\nPrediction: {label} ({confidence * 100:.1f}%)\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "    return label, confidence, original, ela_img\n",
        "\n",
        "def predict_image_freq(img_path):\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"Error: File not found -> {img_path}\")\n",
        "        return \"Unknown\", 0.0, None\n",
        "\n",
        "    freq_map = compute_frequency_map(img_path)\n",
        "    freq_tensor = freq_map[np.newaxis, ..., np.newaxis]\n",
        "    pred = freq_model.predict(freq_tensor)\n",
        "    label = \"Forged\" if np.argmax(pred) == 1 else \"Real\"\n",
        "    confidence = float(np.max(pred))\n",
        "    return label, confidence, freq_map\n",
        "\n",
        "import random\n",
        "\n",
        "def get_random_images_from_split(split_name=\"test\", num_images=10):\n",
        "    \"\"\"Get random images from given split ('test' or 'validation').\"\"\"\n",
        "    all_images = []\n",
        "\n",
        "    for class_name in (\"fake\", \"real\"):\n",
        "        folder = os.path.join(DATASET_PATH, split_name, class_name)\n",
        "        if os.path.isdir(folder):\n",
        "            files = [os.path.join(folder, f) for f in os.listdir(folder)\n",
        "                     if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
        "            all_images.extend(files)\n",
        "        else:\n",
        "            print(f\"Missing folder: {folder}\")\n",
        "\n",
        "    if len(all_images) == 0:\n",
        "        print(f\"No {split_name} images found!\")\n",
        "        return []\n",
        "\n",
        "    num_to_select = min(num_images, len(all_images))\n",
        "    selected = random.sample(all_images, num_to_select)\n",
        "    print(f\"Randomly selected {num_to_select} images from {len(all_images)} available {split_name} images\\n\")\n",
        "    return selected\n",
        "\n",
        "# Choose source split: 'test' or 'validation'\n",
        "SOURCE_SPLIT = \"test\"  # change to \"validation\" to sample validation images\n",
        "\n",
        "# Get random images from chosen split\n",
        "image_files = get_random_images_from_split(split_name=SOURCE_SPLIT, num_images=4)\n",
        "\n",
        "# Add 1 hardcoded image for comparison (only if it exists in dataset)\n",
        "hardcoded_image = \"./dataset/test/fake/dog_forged.jpg\"\n",
        "if os.path.exists(hardcoded_image):\n",
        "    image_files = [hardcoded_image] + image_files\n",
        "\n",
        "# 2. Loop through the list\n",
        "for file_path in image_files:\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        continue\n",
        "\n",
        "    # Get predictions without separate plots\n",
        "    ela_label, ela_conf, original, ela_img = predict_image(file_path, show=False)\n",
        "    freq_label, freq_conf, freq_map = predict_image_freq(file_path)\n",
        "\n",
        "    # Ensemble prediction (simple average)\n",
        "    ela_tensor = (np.array(ela_img) / 255.0)[np.newaxis, ...]\n",
        "    freq_tensor = freq_map[np.newaxis, ..., np.newaxis]\n",
        "    ela_probs = model.predict(ela_tensor)\n",
        "    freq_probs = freq_model.predict(freq_tensor)\n",
        "    ensemble_probs = (ela_probs + freq_probs) / 2.0\n",
        "    ensemble_label = \"Forged\" if np.argmax(ensemble_probs) == 1 else \"Real\"\n",
        "    ensemble_conf = float(np.max(ensemble_probs))\n",
        "\n",
        "    if original is None or freq_map is None or ela_img is None:\n",
        "        continue\n",
        "\n",
        "    # Compute band energies for display\n",
        "    energy = band_energy_stats(freq_map)\n",
        "\n",
        "    # Combined visualization: Original | ELA | Frequency with labels\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    axes[0].imshow(original)\n",
        "    axes[0].set_title(\"Original\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(ela_img)\n",
        "    axes[1].set_title(f\"ELA: {ela_label} ({ela_conf * 100:.1f}%)\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    axes[2].imshow(freq_map, cmap=\"magma\")\n",
        "    axes[2].set_title(\n",
        "        f\"Freq: {freq_label} ({freq_conf * 100:.1f}%)\\n\"\n",
        "        f\"Ensemble: {ensemble_label} ({ensemble_conf * 100:.1f}%)\\n\"\n",
        "        f\"low/mid/high: {energy['low']:.3f} / {energy['mid']:.3f} / {energy['high']:.3f}\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"File: {file_path}\")\n",
        "    print(\n",
        "        f\"ELA: {ela_label} ({ela_conf * 100:.1f}%) | \"\n",
        "        f\"Freq: {freq_label} ({freq_conf * 100:.1f}%) | \"\n",
        "        f\"Ensemble: {ensemble_label} ({ensemble_conf * 100:.1f}%)\")\n",
        "    print(\"-\" * 60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}